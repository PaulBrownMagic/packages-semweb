---+ Document hookable rdf_load/2

---+ Concurrent version of RDF-DB.

---++ Dealing with predicate clouds:

  * Predicate clouds represent a set of interlinked predicates, regardless
    of the generation.
  * A predicate-cloud has
	- A linked list of lifespan+reachability-matrices
  * If two predicate clouds, both having predicates needs merging:
	- Identify the smallest cloud
	- Create new predicates as clones from the old predicates
	- Clone triples to the new predicates.


  TBD: How does all this relate to generation-based life-time?

  * Have the link on predicates + generation and have immutable clouds
    - Array of generation-ranges to clouds
      - Start searching this from the latest
      - Remove on GC
      - If predicate-hash must change at generation X, copy triples
    - Adding/deleting a triple inside a cloud:
      1. Create a copy
      2. Set new one from current generation on all predicates
    - Adding a triples that joins two clouds
      2. Create new cloud with all triples and hash of `largest'
      3. Copy triples to new hash
      4. Set new one from current generation on all predicates.
    - Delete a triples that splits a cloud
      1. Create two new clouds.  Largest takes hash of old.
      2. Copy triples of smaller to hash of new cloud.
      3. Set new clouds on current generation on all predicates.

---++ Transaction semantics

  * All goals in a transaction see the database at the generation of the
  transaction start.
  * All goals in a _nested_ transaction see changes done by the parent
  transaction upto the start of the nested transaction.
  * Update semantics
    - A transaction maintains a list of affected triples.
    - A transaction is assigned a transaction generation, which count
      from near the maximum generation.
      - Each added triple is born at the transaction-generation
      - Each triples deleted died at the transaction-generation
    - If a transaction is _committed_ we scan the affected triples and
      - Each added triple is born at the current generation
      - Each deleted triple died at the current generation
    - If a transaction is _rolled_back_
      - Each added triple is born at the max generation
	- GC will take care of them
      - Each deleted triple died at the max generation (as initial)

  * Transaction generation
    - Must be far enough away from `now'; allocated near the end.
    - All triples in a transaction are from the same generation.
    - Nested transactions need a generation > parent
    - Multiple threads may run multiple transactions concurrently.
      - Groups: max-threads, max-nested?  Ok: 1000*1000 = 1m is still
        nothing.
      - Outer transaction visible: generation of start
      - Inner transaction visible: generation of start of outer +
        generations of parent transactions.

---+ Adding triples

  - Consider distribution of work between link_triple() and
    add_triples().  There is a lot of room for optimization here.
  - Speedup atom-table handling in Prolog
    - Atomic atom-reference update
    - Eventually: lock-free access to existing atoms

---+ Deleting triples

  - Set deleted generation to current; increment current generation.
  - GC does the remainder of the admin updates.

---+ Duplicates:

  - Test for duplicates; set flag on all of them.			[OK]
  - Avoid duplicate answers by maintaining a table, only adding
    triples that are flagged as duplicates.
  - Leave resetting the duplicate flag to GC:
    - If a triple marked as duplicate is erased, check
      whether alternatives remain in the DB.

---+ Hash-table design

  - Implement optimization (like for triples for additional tables)
	- resource-db
	- predicate-db
	- graph-db

  - Perform expensive tests for need to rehash in a thread.


---+ References

Lock-free library:	http://www.liblfds.org/
Useful stuff:		http://eternallyconfuzzled.com/tuts/datastructures/

