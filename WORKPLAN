---+ Concurrent RDF workplan

  * Establish triple-GC						[OK]

  * Establish expansion of triple hash-tables			[OK]

  * Remove old locking code.					[OK]

  * Establish compatible broadcasting				[OK]

  * Duplicate suppression by maintaining a table of duplicate
    answers.							[OK]

  * Deal with subPropertyOf predicate clouds			[OK]

  * Cleanup reachability matrices in GC.  Fairly trivial: just delete
    them if their lifespan has passed.  Except for concurrency issues,
    we do not have to be cautious because they will be recreated anyway.

  * Deal with rdf_update/4,5.					[OK]

  * Optimize the following tables in GC (i.e., by cloning older
    objects into new ones):
	- resource-db
	- predicate-db
	- graph-db

  * Concurrent load: not that we are already loading some graph
    and make a concurrent load wait for completion by the other
    thread.  This is the same as Prolog loading files concurrently.

  * Test framework
    - Controlled concurrency (test_con.pl).  How to generate a comprehensive
      set of test-cases?

      - Action grammar to generate sequences?
      - Keep shadow admin in Prolog
      - Formalise transaction/snapshot isolation

    - Stress testing
      - Run controlled tests concurrently in transactions?

  * rdf_gc							[OK]
    - Erased triples that cannot really be deleted because a transaction/snapshot
      blocks this.
      - Nothing will change if oldest generation doesn't change.

  * Reachability matrices
    - Transaction-specific matrices must be invalidated after completion
      of the transaction.
      - Just flag them as inivalid?
    - We need matrix-GC.
      - Reclaim invalided?
      - DB: linked lists of clouds?
