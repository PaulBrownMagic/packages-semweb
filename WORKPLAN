---+ Concurrent RDF workplan

  * Establish triple-GC						[OK]

  * Establish expansion of triple hash-tables			[OK]

  * Remove old locking code.					[OK]

  * Establish compatible broadcasting

  * Reconsider handling of duplicate triples.  The problem:
    We have a set of triples with different life-span.  We must return
    one triple as long as the set is not empty for our query
    generation.

    - Old solution: assign a leader.  This is now unfeasible (I think)
    - New solution:
      - Maintain duplicate status, indicating that a predicate MAY have
        duplicates.  This means, set a duplicate flag on a triple if we
	added a duplicate triple.
      - When producing answers, put duplicate-marked triples in a
        (hash-)table and filter new duplicate triples according to
	this table.

    - When is a triple a duplicate that we can discard?  Currently
      if it is the same quadruple.  I think we must also check that
      the triple is in the same transaction, so they either both get
      committed or discarded.

  * Deal with subPropertyOf predicate clouds			[OK]

  * Cleanup reachability matrices in GC.  Fairly trivial: just delete
    them if their lifespan has passed.  Except for concurrency issues,
    we do not have to be cautious because they will be recreated anyway.

    - When creating a matrix (for an older generation?), it must invalidate
      at the right time!  This should be the nearest born/died
      generation of the predicates in the cloud.

  * Test framework
    - Controlled concurrency (test_con.pl).  How to generate a comprehensive
      set of test-cases?

      - Action grammar to generate sequences?
      - Keep shadow admin in Prolog
      - Formalise transaction/snapshot isolation

    - Stress testing
      - Run controlled tests concurrently in transactions?
